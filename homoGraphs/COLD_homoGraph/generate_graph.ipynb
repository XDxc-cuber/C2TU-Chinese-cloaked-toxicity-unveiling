{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../datas/COLD/\"\n",
    "datasets = [\"COLD_base.json\", \"COLD_key.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexiconsDatas = [\"COLD_lexicons.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pypinyin import pinyin\n",
    "\n",
    "chars = set()\n",
    "py2char = {}\n",
    "for dataset in datasets:\n",
    "    with open(data_path + dataset, \"r\", encoding=\"utf-8\") as f:\n",
    "        datas = json.loads(\"\".join(f.readlines()))\n",
    "        for data in datas:\n",
    "            for char in data[\"text\"]:\n",
    "                pys = pinyin(char, style=0, heteronym=True)[0]\n",
    "                if len(pys) == 0 or pys[0] == char or char in chars:\n",
    "                    continue\n",
    "                chars.add(char)\n",
    "                for py in pys:\n",
    "                    if not py in py2char:\n",
    "                        py2char[py] = set()\n",
    "                    py2char[py].add(char)\n",
    "\n",
    "for lexiconsData in lexiconsDatas:\n",
    "    with open(lexiconsData, \"r\", encoding=\"utf-8\") as f:\n",
    "        datas = json.loads(\"\".join(f.readlines()))\n",
    "        for data in datas:\n",
    "            for char in data:\n",
    "                pys = pinyin(char, style=0, heteronym=True)[0]\n",
    "                if len(pys) == 0 or pys[0] == char or char in chars:\n",
    "                    continue\n",
    "                chars.add(char)\n",
    "                for py in pys:\n",
    "                    if not py in py2char:\n",
    "                        py2char[py] = set()\n",
    "                    py2char[py].add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = len(chars)\n",
    "A = np.zeros((N, N), dtype=bool)\n",
    "char2id = {}\n",
    "id2char = list(chars)\n",
    "\n",
    "for i, v in enumerate(id2char):\n",
    "    char2id[v] = i\n",
    "\n",
    "with open(\"char2id.json\", \"x\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(char2id, ensure_ascii=False))\n",
    "with open(\"id2char.json\", \"x\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(id2char, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jinyin(py1, py2, py, nb):\n",
    "    if py1 in py:\n",
    "        for char in py2char.get(py.replace(py1, py2), []):\n",
    "            nb.add(char)\n",
    "    if py2 in py:\n",
    "        for char in py2char.get(py.replace(py2, py1), []):\n",
    "            nb.add(char)\n",
    "for py, chars in py2char.items():\n",
    "    neighbors = set()\n",
    "    for char in chars:\n",
    "        neighbors.add(char)\n",
    "    add_jinyin(\"n\", \"l\", py, neighbors)\n",
    "    add_jinyin(\"zh\", \"z\", py, neighbors)\n",
    "    add_jinyin(\"ch\", \"c\", py, neighbors)\n",
    "    add_jinyin(\"sh\", \"s\", py, neighbors)\n",
    "    add_jinyin(\"ng\", \"n\", py, neighbors)\n",
    "    \n",
    "    neighbors = list(neighbors)\n",
    "    for i in range(len(neighbors)-1):\n",
    "        for j in range(i+1, len(neighbors)):\n",
    "            id_i, id_j = char2id[neighbors[i]], char2id[neighbors[j]]\n",
    "            A[id_i, id_j] = A[id_j, id_i] = 1\n",
    "# 加入自环，汉字和其本身为近音关系\n",
    "for i in range(N):\n",
    "    A[i, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"homoGraphA.npy\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163969"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
